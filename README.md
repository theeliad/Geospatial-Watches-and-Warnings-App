# About Me: Geospatial Flood Watches and Weather Web Application
 This is a Climatebase Capstone Project

This project presents a comprehensive web application for predicting coastal flood risk using machine learning models and NOAA data. The application is built using Python tools such as Streamlit, LSTM model, NOAA API, NWS API, Folium, and Matplotlib.

# Project Overview

The project involves developing a three-step workflow:

1.  **Loading Historical Data**: Fetching historical data from NOAA using the NOAA API.
2.  **Training an LSTM Model**: Training an LSTM model on the historical data to predict future flood risk.
3.  **Making Live Predictions**: Making live predictions using recent NOAA data and NWS precipitation forecasts.

# Technical Details

*   Python Tools: Streamlit, LSTM model, NOAA API, NWS API, Folium, and Matplotlib.
*   Machine Learning Model: LSTM model trained on historical data to predict future flood risk.
*   Data Sources: NOAA API and NWS API for fetching historical and live data.

Geospatial Watches and Weather Web Application Overview
===========================================================

## üóÇÔ∏è **Module Architecture**

| Module | Purpose | Key Functions |
|--------|---------|---------------|
| **`main.py`** | Streamlit UI, user flow orchestration | Station selection, 3-step workflow (Load ‚Üí Train ‚Üí Predict) |
| **`stations_df_func.py`** | Station metadata loader | `get_stations_df()` ‚Üí Returns DataFrame with station_id, name, lat, lon, state |
| **`data_fetcher.py`** | NOAA water-level fetcher + flood classification | `fetch_noaa_water()`, `get_flood_levels_from_noaa()`, `classify_flood_risk()` |
| **`data_loader.py`** | Historical data loader & cache manager | `load_noaa_historical()`, `load_last_hours_from_cache()` |
| **`model_trainer.py`** | LSTM model training (univariate: water level only) | `train_model()`, `create_lstm_sequences()`, `StreamlitCallback()` |
| **`predictor.py`** | Live prediction orchestrator | `run_live_prediction()`, `_calculate_precipitation_impact()` |
| **`nws_fetcher.py`** | NWS precipitation forecast retriever | `get_precipitation_forecast(lat, lon, hours)` |

______________________________________________________________________________

# Purpose
main.py
UI, user flow, orchestration of all steps

data_fetcher.py
Retrieve NOAA water-level data + flood thresholds + risk classification

data_loader.py
Historical & live data loading, simulation fallback

model_trainer.py
LSTM model definition, training, progress callbacks

predictor.py (not shown above but used by main.py)
Loads trained model & runs live prediction

nws_fetcher.py
Fetches NWS precipitation forecast & calculates impacts

stations_df_func.py
Loads station metadata used in dropdowns & maps

______________________________________________________________________________

# Three-Step Loop

The application follows a clean three-step loop:

1.  Load Historical Data
Uses load_noaa_historical() to fetch historical data from NOAA.
Saves the data to `data/historical/<station>_historical.csv`.

2.  Train Machine Learning Model
Utilizes model_trainer.train_model() to train the machine learning model.
Loads the historical data from Step 1.
Saves the trained model to models/<station>_flood_model.pkl.

3.  Live Prediction
    *   Uses predictor.run_live_prediction() to make live predictions.
    *   Loads the trained model from Step 2.
    *   Loads live single-timestamp placeholder observation.
    *   Predicts flood probability.

# üåä Comprehensive Web Application Architecture & Workflow
---

## üîÑ Complete User Workflow

### Step 1: Station Selection
```
User Action:
‚îú‚îÄ Select State (dropdown)
‚îú‚îÄ Select Station (dropdown)
‚îî‚îÄ View station info + map

Backend:
‚îú‚îÄ stations_df_func.get_stations_df()
‚îÇ   ‚îî‚îÄ Returns: station_id, station_name, state, latitude, longitude, station_type
‚îî‚îÄ Display station metadata + Folium map
```

---

### Step 2: Load Historical Data
```
User Action:
‚îî‚îÄ Click "üì• Load 1 Year of Historical Data"

Backend Flow:
main.py
  ‚îî‚îÄ Calls: data_loader.load_noaa_historical(station_id, years=1)
       ‚îÇ
       ‚îî‚îÄ Calls: data_fetcher.fetch_noaa_water(station_id, start_date, end_date)
            ‚îÇ
            ‚îú‚îÄ Uses: noaa_coops.Station(station_id).get_data(product="water_level")
            ‚îÇ
            ‚îú‚îÄ Handles column name variations:
            ‚îÇ   ‚Ä¢ If columns = ["t", "v"] ‚Üí rename to ["date_time", "water_level"]
            ‚îÇ   ‚Ä¢ If columns = ["date_time", "water_level"] ‚Üí keep as-is
            ‚îÇ   ‚Ä¢ If columns = ["time", "value"] ‚Üí rename to ["date_time", "water_level"]
            ‚îÇ
            ‚îî‚îÄ Returns: DataFrame with ["date_time", "water_level"]

       ‚îî‚îÄ Saves to: data/historical/{station_id}_historical_1y.csv

UI Output:
‚îú‚îÄ Success message: "‚úî Loaded {N} water-level records"
‚îú‚îÄ Display: df.head() table
‚îî‚îÄ Display: Line chart of water_level over time
```

File Structure After Step 2:
```
data/
‚îî‚îÄ‚îÄ historical/
    ‚îî‚îÄ‚îÄ 8724580_historical_1y.csv  # Example for Key West station
```

---

### Step 3: Train LSTM Model
```
User Action:
‚îî‚îÄ Click "üß† Train LSTM Model"

Backend Flow:
main.py
  ‚îî‚îÄ Calls: model_trainer.train_model(station_id, years=1, seq_len=72, epochs=20)
       ‚îÇ
       ‚îú‚îÄ Loads: data/historical/{station_id}_historical_1y.csv
       ‚îÇ
       ‚îú‚îÄ Validates: "water_level" column exists
       ‚îÇ
       ‚îú‚îÄ Preprocessing:
       ‚îÇ   ‚îú‚îÄ Scale data: MinMaxScaler(feature_range=(0, 1))
       ‚îÇ   ‚îú‚îÄ Save scaler: models/{station_id}_waterlevel_scaler.pkl
       ‚îÇ   ‚îî‚îÄ Create sequences: create_lstm_sequences(data, seq_len=72)
       ‚îÇ       ‚Ä¢ X shape: (num_samples, 72, 1)  # 72 hours of water level
       ‚îÇ       ‚Ä¢ y shape: (num_samples, 1)      # Next hour's water level
       ‚îÇ
       ‚îú‚îÄ Train/Test Split: 80% train, 20% test
       ‚îÇ
       ‚îú‚îÄ LSTM Architecture:
       ‚îÇ   ‚îî‚îÄ LSTM(50, return_sequences=True) ‚Üí Dropout(0.2)
       ‚îÇ       ‚îî‚îÄ LSTM(50, return_sequences=False) ‚Üí Dropout(0.2)
       ‚îÇ           ‚îî‚îÄ Dense(25, relu) ‚Üí Dense(1)
       ‚îÇ
       ‚îú‚îÄ Training:
       ‚îÇ   ‚îú‚îÄ Optimizer: Adam
       ‚îÇ   ‚îú‚îÄ Loss: Mean Squared Error
       ‚îÇ   ‚îú‚îÄ Callbacks: EarlyStopping(patience=5), ModelCheckpoint, StreamlitCallback
       ‚îÇ   ‚îî‚îÄ Progress bar updates in Streamlit UI
       ‚îÇ
       ‚îî‚îÄ Saves:
           ‚îú‚îÄ models/{station_id}_waterlevel_lstm.keras  (or .h5)
           ‚îî‚îÄ models/{station_id}_waterlevel_scaler.pkl

UI Output:
‚îú‚îÄ Progress bar: "Training Epoch 15/20 ‚Äì Validation Loss: 0.0023"
‚îî‚îÄ Success message: "‚úî LSTM Model trained and saved to models/{station_id}_waterlevel_lstm.keras"
```

File Structure After Step 3:
```
models/
‚îú‚îÄ‚îÄ 8724580_waterlevel_lstm.keras
‚îî‚îÄ‚îÄ 8724580_waterlevel_scaler.pkl
```

---

### Step 4: Live Water Level Forecast
```
User Action:
‚îî‚îÄ Click "üîÆ Forecast Next Hour's Water Level"

Backend Flow:
main.py
  ‚îî‚îÄ Calls: predictor.run_live_prediction(station_id, seq_len=72)
       ‚îÇ
       ‚îú‚îÄ PHASE 1: Load Model & Scaler
       ‚îÇ   ‚îú‚îÄ Load: models/{station_id}_waterlevel_lstm.keras
       ‚îÇ   ‚îî‚îÄ Load: models/{station_id}_waterlevel_scaler.pkl
       ‚îÇ
       ‚îú‚îÄ PHASE 2: Get Recent Water Level Data
       ‚îÇ   ‚îî‚îÄ Calls: data_loader.load_last_hours_from_cache(station_id, hours=72)
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îú‚îÄ Searches for:
       ‚îÇ        ‚îÇ   ‚Ä¢ data/historical/{station_id}_historical_1y.csv
       ‚îÇ        ‚îÇ   ‚Ä¢ data/historical/{station_id}_historical_5y.csv
       ‚îÇ        ‚îÇ   ‚Ä¢ data/historical/{station_id}_historical.csv
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îú‚îÄ Filters: Last 72 hours from current UTC time
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îî‚îÄ Returns: DataFrame with ["date_time", "water_level"]
       ‚îÇ
       ‚îú‚îÄ PHASE 3: Base LSTM Prediction
       ‚îÇ   ‚îú‚îÄ Prepare input: Scale last 72 hours of water_level
       ‚îÇ   ‚îú‚îÄ Reshape: (1, 72, 1)
       ‚îÇ   ‚îú‚îÄ Predict: model.predict(X_pred)
       ‚îÇ   ‚îú‚îÄ Inverse transform: scaler.inverse_transform()
       ‚îÇ   ‚îî‚îÄ Result: base_lstm_prediction_ft (e.g., 2.45 ft)
       ‚îÇ
       ‚îú‚îÄ PHASE 4: Fetch Precipitation Forecast
       ‚îÇ   ‚îú‚îÄ Get station coordinates:
       ‚îÇ   ‚îÇ   ‚îî‚îÄ Calls: stations_df_func.get_stations_df()
       ‚îÇ   ‚îÇ        ‚îî‚îÄ Extract: lat, lon for station_id
       ‚îÇ   ‚îÇ
       ‚îÇ   ‚îî‚îÄ Calls: nws_fetcher.get_precipitation_forecast(lat, lon, hours=12)
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îú‚îÄ NWS API: /points/{lat},{lon}
       ‚îÇ        ‚îÇ   ‚îî‚îÄ Get: forecastGridData URL
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îú‚îÄ Fetch: quantitativePrecipitation (hourly)
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îî‚îÄ Returns: DataFrame with:
       ‚îÇ            ‚Ä¢ valid_time (datetime)
       ‚îÇ            ‚Ä¢ precipitation_probability (%)
       ‚îÇ            ‚Ä¢ precipitation_amount (inches, if available)
       ‚îÇ
       ‚îú‚îÄ PHASE 5: Calculate Precipitation Impact
       ‚îÇ   ‚îî‚îÄ Calls: _calculate_precipitation_impact(precip_df)
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îú‚îÄ Heuristic Rules:
       ‚îÇ        ‚îÇ   ‚Ä¢ max_prob >= 80% ‚Üí +2.0 ft
       ‚îÇ        ‚îÇ   ‚Ä¢ max_prob >= 60% ‚Üí +1.0 ft
       ‚îÇ        ‚îÇ   ‚Ä¢ max_prob >= 30% ‚Üí +0.5 ft
       ‚îÇ        ‚îÇ   ‚Ä¢ else ‚Üí 0.0 ft
       ‚îÇ        ‚îÇ
       ‚îÇ        ‚îî‚îÄ Returns: {
       ‚îÇ              '


# Machine Learning Model:

LSTM Machine Learning (Official)

The official version uses an LSTM (Long Short-Term Memory) machine learning model to predict the water level at a given time. The model is trained on historical data such as water level, precipitation, temperature, and wind speed. The model is designed to answer "What will the water level be at 3:00 PM?" and is well-suited for this task due to its ability to capture long-term dependencies in the data.

The LSTM machine learning model used in the official version is a type of recurrent neural network (RNN) that is particularly well-suited for time series forecasting tasks. The model is trained on a sequence of data points and makes predictions based on the patterns and relationships it has learned from the data.

The LSTM model is particularly well-suited for this task because it can capture long-term dependencies in the data and is robust to noise and variability. The model is also relatively fast to train and can handle large datasets.

Model Trainer (LSTM)

The model_trainer.py module contains the train_model() function, which trains an LSTM model to predict the water level at a given time. The function takes in the station ID, sequence length, epochs, batch size, and progress bar as inputs. It loads the historical data, scales the data, creates sequences, trains the model, and saves the trained model and scaler to disk.

Predictor (LSTM)

The predictor.py module contains the run_live_prediction() function, which takes in the station ID, sequence length, and live data as inputs. It loads the trained model, scales the live data, makes predictions, and returns the predicted water level and flood risk.

Accuracy Comparison

For predicting "What will the water level be at 3:00 PM?", the LSTM model will be more accurate due to its ability to capture long-term dependencies in the data.

NOAA Live Data Fetcher and Loader 

The data_fetcher.py module contains the load_noaa_live() function, which fetches the latest NOAA live measurements for a given station. The function takes in the station ID and sequence length as inputs and returns the live data.

The data_loader.py module contains the load_noaa_historical() function, which fetches historical data from NOAA for a given station. The function takes in the station ID and lookback days as inputs and returns the historical data.

Plotting Function 

The plot_results() function is used to plot the actual vs. predicted water levels for visual inspection. The function takes in the actual and predicted water levels as inputs and plots them using matplotlib.

# Data Sources

The project uses two data sources:

NOAA API: For fetching historical and live data.
NWS API: For fetching precipitation forecasts.
